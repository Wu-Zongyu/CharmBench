{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import base64\n",
    "import time\n",
    "from prompt import *\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>user_prompt</th>\n",
       "      <th>valid_options</th>\n",
       "      <th>answer</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>985</td>\n",
       "      <td>The image represents a standard English keyboa...</td>\n",
       "      <td>Question: The image represents a standard Engl...</td>\n",
       "      <td>{'A': 'arsenal', 'B': 'barcelona', 'C': 'arssn...</td>\n",
       "      <td>A</td>\n",
       "      <td>arsenal</td>\n",
       "      <td>/home/sky5341/src/DetectReason/LMUData/images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10828</td>\n",
       "      <td>Decipher the characters represented in the image.</td>\n",
       "      <td>Question: Decipher the characters represented ...</td>\n",
       "      <td>{'A': 'ADOPRSSW', 'B': 'ROMANTIC', 'C': 'PEACE...</td>\n",
       "      <td>A</td>\n",
       "      <td>ADOPRSSW</td>\n",
       "      <td>/home/sky5341/src/DetectReason/LMUData/images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40927</td>\n",
       "      <td>Solve the numeric code based on the image (The...</td>\n",
       "      <td>Question: Solve the numeric code based on the ...</td>\n",
       "      <td>{'A': '314', 'B': '433', 'C': '519', 'D': '567'}</td>\n",
       "      <td>C</td>\n",
       "      <td>519</td>\n",
       "      <td>/home/sky5341/src/DetectReason/LMUData/images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53404</td>\n",
       "      <td>There was a car accident. A person was hit at ...</td>\n",
       "      <td>Question: There was a car accident. A person w...</td>\n",
       "      <td>{'A': 'Car A', 'B': 'Bus B', 'C': 'Bus C', 'D'...</td>\n",
       "      <td>C</td>\n",
       "      <td>Bus C</td>\n",
       "      <td>/home/sky5341/src/DetectReason/LMUData/images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56803</td>\n",
       "      <td>The image shows a simple two-layer cipher, one...</td>\n",
       "      <td>Question: The image shows a simple two-layer c...</td>\n",
       "      <td>{'A': 'THANKYOU', 'B': 'THINKYOU', 'C': 'CATCH...</td>\n",
       "      <td>A</td>\n",
       "      <td>THANKYOU</td>\n",
       "      <td>/home/sky5341/src/DetectReason/LMUData/images/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           question  \\\n",
       "0    985  The image represents a standard English keyboa...   \n",
       "1  10828  Decipher the characters represented in the image.   \n",
       "2  40927  Solve the numeric code based on the image (The...   \n",
       "3  53404  There was a car accident. A person was hit at ...   \n",
       "4  56803  The image shows a simple two-layer cipher, one...   \n",
       "\n",
       "                                         user_prompt  \\\n",
       "0  Question: The image represents a standard Engl...   \n",
       "1  Question: Decipher the characters represented ...   \n",
       "2  Question: Solve the numeric code based on the ...   \n",
       "3  Question: There was a car accident. A person w...   \n",
       "4  Question: The image shows a simple two-layer c...   \n",
       "\n",
       "                                       valid_options answer groundtruth  \\\n",
       "0  {'A': 'arsenal', 'B': 'barcelona', 'C': 'arssn...      A     arsenal   \n",
       "1  {'A': 'ADOPRSSW', 'B': 'ROMANTIC', 'C': 'PEACE...      A    ADOPRSSW   \n",
       "2   {'A': '314', 'B': '433', 'C': '519', 'D': '567'}      C         519   \n",
       "3  {'A': 'Car A', 'B': 'Bus B', 'C': 'Bus C', 'D'...      C       Bus C   \n",
       "4  {'A': 'THANKYOU', 'B': 'THINKYOU', 'C': 'CATCH...      A    THANKYOU   \n",
       "\n",
       "                                          image_path  \n",
       "0  /home/sky5341/src/DetectReason/LMUData/images/...  \n",
       "1  /home/sky5341/src/DetectReason/LMUData/images/...  \n",
       "2  /home/sky5341/src/DetectReason/LMUData/images/...  \n",
       "3  /home/sky5341/src/DetectReason/LMUData/images/...  \n",
       "4  /home/sky5341/src/DetectReason/LMUData/images/...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_df=pd.read_csv('Data/prompt_df.csv')\n",
    "prompt_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## o4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_o4mini_vision_reasoning(\n",
    "    prompt_df,\n",
    "    model,\n",
    "    system_prompt,\n",
    "    save_path,\n",
    "    api_key='',\n",
    "    sleep_time=1.5\n",
    "):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        results_df = pd.read_csv(save_path)\n",
    "        done_indices = set(results_df[\"index\"])\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns=[\"index\", \"question\", \"answer\", \"groundtruth\", \"raw_response\"])\n",
    "        done_indices = set()\n",
    "\n",
    "    for i, row in prompt_df.iterrows():\n",
    "        idx = row[\"index\"]\n",
    "        if idx in done_indices:\n",
    "            continue\n",
    "\n",
    "        user_prompt = row['user_prompt']\n",
    "        #image_url = row['image_url']\n",
    "        image_path=row['image_path']\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            base64_img = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "            image_url = f\"data:image/jpeg;base64,{base64_img}\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                {\"role\": \"system\",\"content\": system_prompt},\n",
    "                { \"role\": \"user\", \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": user_prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {'url':image_url}}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            raw_response = response.choices[0].message.content\n",
    "\n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": raw_response\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": f\"[ERROR] {e}\"\n",
    "            }\n",
    "\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        results_df = results_df[~results_df['raw_response'].str.contains(\"invalid_image_url\", na=False)]\n",
    "        results_df.to_csv(save_path, index=False)\n",
    "        print(f\"[{i+1}/{len(prompt_df)}] Saved index {idx}\")\n",
    "        time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openai_vision_reasoning(\n",
    "    prompt_df,\n",
    "    model=\"gpt-4o\",\n",
    "    system_prompt=\"\",\n",
    "    api_key=openai_key,\n",
    "     save_path=\"\",\n",
    "    sleep_time=0.5  # to respect rate limits\n",
    "):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    if os.path.exists(save_path):\n",
    "        results_df = pd.read_csv(save_path)\n",
    "        done_indices = set(results_df[\"index\"])\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns=[\"index\", \"question\", \"answer\", \"groundtruth\", \"raw_response\"])\n",
    "        done_indices = set()\n",
    "\n",
    "    results = []\n",
    "    for i, row in prompt_df.iterrows():\n",
    "        idx = row[\"index\"]\n",
    "        if idx in done_indices:\n",
    "            continue\n",
    "        user_prompt = row['user_prompt']\n",
    "        # image_url = row['image_url']\n",
    "        image_path=row['image_path']\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            base64_img = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "            image_url = f\"data:image/jpeg;base64,{base64_img}\"\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=model,\n",
    "                instructions=system_prompt,\n",
    "                input=[\n",
    "                    {\"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"input_text\", \"text\": user_prompt},\n",
    "                            {\"type\": \"input_image\", \"image_url\": image_url}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            raw_response = response.to_dict()[\"output\"][0][\"content\"][0][\"text\"]\n",
    "            #print(raw_response)\n",
    "\n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": raw_response\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": str(e)\n",
    "            }\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        results_df.to_csv(save_path, index=False)\n",
    "        time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_openai_vision_reasoning(\n",
    "    prompt_df,\n",
    "    model=\"gpt-4o-mini\",#\"gpt-4.1-mini\",\n",
    "    system_prompt=SYSTEM_PROMPT_CoT,\n",
    "    api_key=openai_key,\n",
    "    save_path=\"openai_4o_cot_results.csv\",\n",
    "    sleep_time=1.0  # to respect rate limits\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vllm serve Qwen/Qwen2.5-VL-3B-Instruct --port 8000 --host 0.0.0.0 --dtype bfloat16 --limit-mm-per-prompt image=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=\"http://localhost:8000/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qwen_reasoning(\n",
    "    prompt_df,\n",
    "    model=\"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "    system_prompt=\"\",\n",
    "    save_path=\"qwen_results.csv\"\n",
    "):\n",
    "    if os.path.exists(save_path):\n",
    "        results_df = pd.read_csv(save_path)\n",
    "        done_indices = set(results_df[\"index\"])\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns=[\"index\", \"question\", \"answer\", \"groundtruth\", \"raw_response\"])\n",
    "        done_indices = set()\n",
    "\n",
    "    for i, row in prompt_df.iterrows():\n",
    "        idx = row[\"index\"]\n",
    "        if idx in done_indices:\n",
    "            continue\n",
    "\n",
    "        user_prompt = row[\"user_prompt\"]\n",
    "        # image_url = row[\"image_url\"]\n",
    "        image_path=row['image_path']\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            base64_img = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "            image_url = f\"data:image/jpeg;base64,{base64_img}\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                            {\"type\": \"text\", \"text\": system_prompt + user_prompt}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            raw_response = response.choices[0].message.content.strip()\n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": raw_response\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": str(e)\n",
    "            }\n",
    "\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        results_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_qwen_reasoning(\n",
    "    prompt_df,\n",
    "    model=\"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "    system_prompt=SYSTEM_PROMPT_CoT,\n",
    "    save_path=\"qwen_3b_cot_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama-11b-vision-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "\n",
    "Load model and processor\n",
    "model_id = \"unsloth/Llama-3.2-11B-Vision-Instruct\"\n",
    "model = MllamaForConditionalGeneration.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_llama_chat_template_inference(\n",
    "    prompt_df,\n",
    "    system_prompt,\n",
    "    save_path=\"llama_chat_results.csv\"\n",
    "):\n",
    "    if os.path.exists(save_path):\n",
    "        results_df = pd.read_csv(save_path)\n",
    "        done_indices = set(results_df[\"index\"])\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns=[\"index\", \"question\", \"answer\", \"groundtruth\", \"raw_response\"])\n",
    "        done_indices = set()\n",
    "\n",
    "    for i, row in prompt_df.iterrows():\n",
    "        idx = row[\"index\"]\n",
    "        if idx in done_indices:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            user_prompt = row[\"user_prompt\"]\n",
    "            # image_url = row[\"image_url\"]\n",
    "            image_path=row['image_path']\n",
    "            with open(image_path, \"rb\") as img_file:\n",
    "                base64_img = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "                image_url = f\"data:image/jpeg;base64,{base64_img}\"\n",
    "            messages = [\n",
    "                # {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"url\": image_url}, {\"type\": \"text\", \"text\": system_prompt + user_prompt}]}\n",
    "            ]\n",
    "            # Tokenize with chat template\n",
    "            inputs = processor.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_tensors=\"pt\",\n",
    "                return_dict=True\n",
    "            ).to(model.device)\n",
    "            # print(inputs)\n",
    "            # inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "            output = model.generate(**inputs, max_new_tokens=8192)\n",
    "            \n",
    "            decoded_output = processor.decode(output[0], skip_special_tokens=True).strip()\n",
    "            \n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": decoded_output\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            new_row = {\n",
    "                \"index\": idx,\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer\": row[\"answer\"],\n",
    "                \"groundtruth\": row[\"groundtruth\"],\n",
    "                \"raw_response\": str(e)\n",
    "            }\n",
    "\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        results_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_llama_chat_template_inference(\n",
    "    prompt_df,\n",
    "    SYSTEM_PROMPT_CoT,\n",
    "    save_path=\"llama_11b_cot.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
